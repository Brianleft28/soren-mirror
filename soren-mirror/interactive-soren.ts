import inquirer from 'inquirer';
import chalk from 'chalk';
import { GoogleGenerativeAI } from "@google/generative-ai";
import dotenv from "dotenv";
import fs from 'fs';
import path from 'path';

// --- IMPORTS DEL N√öCLEO ---
import { Chronos } from './src/core/chronos';
import { Archivist } from './src/core/archivist';
import { StressManager } from './src/core/stress-manager';
import { LocalAgent, SorenMode } from './src/core/ollama-client';
import { GlobalMemory } from './src/core/memory'; 
import { getAvailableModels } from './src/core/gemini-client';
import { IdentityManager } from './src/core/identity';

dotenv.config();

const API_KEY = process.env.GEMINI_API_KEY || "";
const genAI = new GoogleGenerativeAI(API_KEY);

let activeGeminiModel: any;           
let localBrain: LocalAgent;           

async function selectModel() {
    console.log(chalk.yellow("üì° Conectando con Google AI..."));
    try {
        const models = await getAvailableModels();
        const sortedModels = models.sort((a, b) => 
             (b.displayName.includes('1.5') ? 1 : 0) - (a.displayName.includes('1.5') ? 1 : 0)
        );

        const { selectedModelName } = await inquirer.prompt([{
            type: 'list',
            name: 'selectedModelName',
            message: 'üß† Selecciona el CEREBRO L√ìGICO (Gemini):',
            choices: sortedModels.map(m => ({
                name: `${m.displayName} ${chalk.gray(`(${m.name.replace('models/', '')})`)}`,
                value: m.name.replace('models/', '')
            })),
            pageSize: 10
        }]);

        activeGeminiModel = genAI.getGenerativeModel({ model: selectedModelName });
        console.log(chalk.green(`‚úÖ N√∫cleo L√≥gico: ${selectedModelName}`));
        
        localBrain = new LocalAgent('dolphin-llama3'); 
        console.log(chalk.green(`‚úÖ N√∫cleo Local: Dolphin-Llama3 (Ready)`));

    } catch (error) {
        console.error("‚ùå Fallo en selecci√≥n. Usando defaults.");
        activeGeminiModel = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
        localBrain = new LocalAgent();
    }
}

// --- PIPELINE H√çBRIDO ---
async function procesarRespuestaHibrida(
    inputUsuario: string, 
    stressLevel: number, 
    memory: GlobalMemory 
): Promise<string> {
    
    const historiaReciente = memory.getRecentHistory(4000);
    
    const promptGemini = `
    HISTORIAL CONTEXTUAL: ${historiaReciente}
    USUARIO: ${inputUsuario}
    INSTRUCCI√ìN: Genera una respuesta t√©cnica, l√≥gica y precisa. Ignora estilo, c√©ntrate en c√≥digo y l√≥gica.
    `;
    
    const chat = activeGeminiModel.startChat();
    const result = await chat.sendMessage(promptGemini);
    const rawContent = result.response.text();

    const promptRefinamiento = `
    INPUT ORIGINAL: "${rawContent}"

    TU IDENTIDAD: S√∏ren Architect (Hacker, Pragm√°tico, Directo).
    TU MISI√ìN:
    1. Reescribe la respuesta anterior adoptando tu identidad.
    2. Nivel de Estr√©s del Usuario: ${stressLevel}/10. 
       ${stressLevel > 7 ? "-> El usuario est√° MUY estresado. S√© breve y calmado." : "-> El usuario est√° calmado. Explayate."}
    3. Elimina frases de relleno.
    4. Si hay c√≥digo, pres√©ntalo sin rodeos.
    5. Prioriza la estructura, claridad y documentaci√≥n.
    6. Docs as code: La documentaci√≥n se trata igual que al c√≥digo.
    `;

    return await localBrain.chat(SorenMode.ARCHITECT, promptRefinamiento);
}

// --- MAIN LOOP ---
async function main() {
    console.clear();
    console.log("üîÆ S√òREN MIRROR - IDENTITY SYSTEM (v4.0) üîÆ");
    
    const identityMgr = new IdentityManager();
    const existingUsers = identityMgr.getExistingIdentities();
    
    let memory: GlobalMemory;
    let currentIdentity = "";

    // 1. LOGIN
    const { loginMode } = await inquirer.prompt([{
        type: 'list',
        name: 'loginMode',
        message: 'Identificaci√≥n de Acceso:',
        choices: [
            ...existingUsers.map(u => ({ name: `üìÇ Cargar perfil: [${u}]`, value: u })),
            { name: '‚ú® Nueva Sesi√≥n (Generar Identidad)', value: 'NEW' }
        ]
    }]);

    if (loginMode === 'NEW') {
        const { firstPrompt } = await inquirer.prompt([{
            type: 'input', name: 'firstPrompt', message: chalk.cyan('Escribe tu primera instrucci√≥n (esto definir√° tu apodo):')
        }]);
        console.log(chalk.gray("Analizando patr√≥n de escritura..."));
        
        currentIdentity = await identityMgr.generateIdentity(firstPrompt);
        console.log(chalk.green(`\nüÜî Identidad Asignada: [ ${chalk.bold(currentIdentity)} ]`));
        
        memory = new GlobalMemory(currentIdentity);
        memory.appendInteraction('USER', firstPrompt);
        
    } else {
        currentIdentity = loginMode;
        console.log(chalk.green(`\n‚úÖ Identidad cargada: ${currentIdentity}`));
        memory = new GlobalMemory(currentIdentity);
    }

    // ‚¨áÔ∏è AQU√ç ES DONDE AGREGAMOS EL STRESS MANAGER VINCULADO AL USUARIO ‚¨áÔ∏è
    const stressTracker = new StressManager(currentIdentity); 
    
    // PREDECIMOS EL FUTURO ANTES DE EMPEZAR
    const baseStress = stressTracker.predictBaseStress();
    if (baseStress > 0) {
        console.log(chalk.magenta(`üìâ [PREDICCI√ìN] Estr√©s hist√≥rico base para hoy: ${baseStress.toFixed(1)}/10`));
        // Truco: Le pasamos un string vac√≠o para "cargar" ese estr√©s inicial en la sesi√≥n
        // (Asumiendo que modificaste StressManager para no bajar el estr√©s si recibe string vac√≠o, 
        // o simplemente confiamos en que el primer prompt ajustar√° el nivel).
    }

    await selectModel(); 

    const chronos = new Chronos();
    const chatHistory: { user: string, soren: string }[] = [];

    console.log(chalk.green(`\n‚úÖ Sistema listo. Escribe 'salir' para terminar.`));

    while (true) {
        if (chronos.shouldInterrupt()) {
            console.log(chalk.redBright("\n‚ö†Ô∏è  [CHRONOS] Fatiga detectada. Cierre forzoso."));
            break; 
        }

        const { prompt } = await inquirer.prompt([{
            type: 'input', name: 'prompt', message: chalk.cyan(`[${currentIdentity}] >`)
        }]);

        if (prompt.toLowerCase() === 'salir') break;

        memory.appendInteraction('USER', prompt);

        // Usamos la instancia local 'stressTracker'
        const currentStress = stressTracker.updateAndGetStress(prompt);
        
        const stressBar = "‚ñà".repeat(Math.ceil(currentStress));
        const stressColor = currentStress > 7 ? chalk.red : chalk.gray;
        console.log(stressColor(`[Stress: ${currentStress.toFixed(1)} ${stressBar}]`));

        process.stdout.write(chalk.gray("Pensando (Nube -> Local)..."));
        
        try {
            const respuesta = await procesarRespuestaHibrida(prompt, currentStress, memory);
            
            process.stdout.write("\r" + " ".repeat(30) + "\r");
            console.log(chalk.magenta('S√∏ren Code: ') + respuesta);

            memory.appendInteraction('S√òREN', respuesta);
            chatHistory.push({ user: prompt, soren: respuesta });

        } catch (error: any) {
            console.error(chalk.red(`‚ùå Error: ${error.message}`));
        }
    }

    if (chatHistory.length > 0) Archivist.saveSession(chatHistory);
    console.log("\nFin de sesi√≥n.");
}

main();