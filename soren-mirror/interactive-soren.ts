import inquirer from 'inquirer';
import chalk from 'chalk';
import { GoogleGenerativeAI } from "@google/generative-ai";
import dotenv from "dotenv";
import fs from 'fs';
import path from 'path';
import { Chronos } from './src/core/chronos';
import { Archivist } from './src/core/archivist';
import { calculateStressLevel } from './src/core/stress-manager';
import { getAvailableModels } from './src/core/gemini-client';

dotenv.config();

const API_KEY = process.env.GEMINI_API_KEY || "";
const genAI = new GoogleGenerativeAI(API_KEY);

let activeModel: any; 

async function getSorenResponse(prompt: string, systemPrompt: string) {
    // Protecci√≥n por si intentamos usarlo antes de elegir
    if (!activeModel) throw new Error("‚ö†Ô∏è El modelo no ha sido inicializado.");

    const chat = activeModel.startChat({
        history: [],
        generationConfig: { maxOutputTokens: 2000 },
        systemInstruction: systemPrompt,
    });

    const result = await chat.sendMessage(prompt);
    return result.response.text();
}

// üëá FUNCI√ìN PARA ELEGIR CEREBRO
async function selectModel() {
    console.log(chalk.yellow("üì° Conectando con Google AI para ver modelos disponibles..."));
    
    try {
        const models = await getAvailableModels();
        
        // Ordenamos para que los modelos m√°s nuevos (1.5) salgan primero
        const sortedModels = models.sort((a, b) => {
             const scoreA = a.displayName.includes('1.5') ? 2 : 1;
             const scoreB = b.displayName.includes('1.5') ? 2 : 1;
             return scoreB - scoreA;
        });

        // Usamos Inquirer para la lista interactiva
        const { selectedModelName } = await inquirer.prompt([
            {
                type: 'list',
                name: 'selectedModelName',
                message: 'üß† Selecciona el cerebro para esta sesi√≥n:',
                choices: sortedModels.map(m => ({
                    name: `${chalk.bold(m.displayName)} ${chalk.gray(`(${m.name.replace('models/', '')})`)}`,
                    value: m.name.replace('models/', '') 
                })),
                pageSize: 12
            }
        ]);

        console.log(chalk.green(`‚úÖ Cerebro activado: ${selectedModelName}\n`));
                activeModel = genAI.getGenerativeModel({ model: selectedModelName });

    } catch (error) {
        console.error(chalk.red("‚ùå Error obteniendo lista. Usando fallback (gemini-1.5-flash)."));
        activeModel = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    }
}

async function main() {
    console.clear();
    console.log("üîÆ S√òREN MIRROR - SYSTEM V2 üîÆ");
    console.log("-------------------------------");

    // üëá LLAMADA DE BLOQUEO (Espera a que elijas antes de seguir)
    await selectModel();

    
    // INICIALIZAR M√ìDULOS COGNITIVOS
    const chronos = new Chronos();    
    // CARGAR PERSONALIDAD "WRITER"
    // ... (resto de tu c√≥digo original: personaPath, basePersona, bucle while, etc.)
    const personaPath = path.join(__dirname, 'docs', 'vision', 'private_persona.md');
    const stressThreshold = 7; // Umbral de estr√©s para activar alertas
    
    
    // Solo aseg√∫rate de copiar el resto de tu funci√≥n main() aqu√≠ abajo
    const basePersona = fs.existsSync(personaPath) 
        ? fs.readFileSync(personaPath, 'utf-8') 
        : "Eres S√∏ren, un editor brutalmente honesto.";

    
    const chatHistory: { user: string, soren: string }[] = [];
    let lastMessageTime = Date.now(); 

    console.log(chalk.green(`\n‚úÖ Conectado. Escribe para comenzar. ('salir' para guardar y terminar)`));

    while (true) {
        if (chronos.shouldInterrupt()) {
            console.log(chalk.redBright("\n\n--- ‚ö†Ô∏è ALERTA DE FATIGA ESTOC√ÅSTICA (CHRONOS) ---"));
            break; 
        }

        const { prompt } = await inquirer.prompt([{
            type: 'input',
            name: 'prompt',
            message: chalk.cyan('Vos:')
        }]);

        if (prompt.toLowerCase() === 'salir') break;

        const stressScore = calculateStressLevel(prompt, lastMessageTime);
        lastMessageTime = Date.now();

        let stressInstruction = "";
        if (stressScore >= stressThreshold) {
            stressInstruction = "\n\nNota: El usuario parece estar bajo un alto nivel de estr√©s. Responde con empat√≠a y ofrece apoyo.";
            console.log(chalk.redBright("‚ö†Ô∏è Nivel de estr√©s detectado en el usuario. Ajustando respuesta..."));
        }

        const finalSystemPrompt = `${basePersona}${stressInstruction}`;

        try {
            process.stdout.write(chalk.gray("S√∏ren piensa..."));
            const response = await getSorenResponse(prompt, finalSystemPrompt);
            process.stdout.write("\r" + " ".repeat(20) + "\r");
            
            console.log(chalk.magenta('S√∏ren: ') + response);
            chatHistory.push({ user: prompt, soren: response });

        } catch (error: any) {
            console.error(chalk.red(`‚ùå Error: ${error.message}`));
        }
    }

    if (chatHistory.length > 0) {
        Archivist.saveSession(chatHistory);
    }

    console.log(chalk.bold("\nFin de la sesi√≥n."));
}

main();